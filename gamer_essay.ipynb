{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luke Witten and Aditi Vinod:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methedology\n",
    "\n",
    "Now that we have our data (conveniently stored as CSV's) we can actually start analyzing our data.\n",
    "\n",
    "Storing our data in this form means that we do not need to re-scrape the data from Reddit every time we want to analyze it, but it also means that the data is not readily accessible by the computer.\n",
    "\n",
    "Luckily reading data from a CSV is not difficult, using the function `csv_to_dict` we can easily convert from a CSV file to a dictionary in python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the dictionary is 17752\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gamer_words\n",
    "\n",
    "def csv_to_dict(file_name):\n",
    "    with open(file_name) as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        word_dict = dict(reader)\n",
    "    return word_dict\n",
    "\n",
    "gamer_dictionary = csv_to_dict(\"gaming.csv\")\n",
    "\n",
    "\n",
    "for word in gamer_dictionary:\n",
    "    value = gamer_dictionary[word]\n",
    "    gamer_dictionary[word] = int(value)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"the length of the dictionary is {len(gamer_dictionary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have access to a dictionary that tells us how many times a word is used in the dataset we collected, but many of these words appear only once or are typos. These results are not particularly useful as we want words that are commonly used by gamers.\n",
    "\n",
    "We can remove words from the dataset who do not show up enough times fairly simply using `remove_too_uncommon()`. Bundled into this function is also code to remove typo words that duplicate themselves and code to remove strings that are far too long such as urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the dictionary is 5061\n"
     ]
    }
   ],
   "source": [
    "#create a new dictionary with only words that appear 3 or more times\n",
    "gamer_dictionary_1 = gamer_words.remove_too_uncommon(gamer_dictionary,3)\n",
    "print(f\"the length of the dictionary is {len(gamer_dictionary_1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is much smaller than the original and likely more representative of words that gamers actually say. \n",
    "\n",
    "If we want to find out which words gamers use most, then all we need to do is find which words appear most frequently in the dataset. Once we have these \"gamer words\" we can compare them against a user's post history to find out if they are a gamer or not.\n",
    "\n",
    "Let's run `find_most_frequent()` to find the 5 most frequently occuring \"gamer words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the five most frequent gamer words are {'the': 6797, 'to': 4351, 'and': 3528, 'a': 3472, 'of': 3008}\n"
     ]
    }
   ],
   "source": [
    "gamer_dictionary_2 = gamer_words.find_most_frequent(gamer_dictionary_1,5)\n",
    "print(f\"the five most frequent gamer words are {gamer_dictionary_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the words that appeared we can see that something is obviously wrong. While there is no doubt that gamers use words like \"a\", \"and\", and \"the\" frequently, nobody would be fooled into believing that these words are unique to the gamer vocabulary. \n",
    "\n",
    "To fully determine what words are unique to the gamer vocabulary, we will need to somehow compare the language dataset from gamers to a language dataset for non-gamers.\n",
    "\n",
    "For our convenience, this data has already been scraped and is stored in `normal_dictionary.csv`\n",
    "\n",
    "~ aditi put something here about our methodology from scraping normal subreddits and what normal subreddits we scraped from~\n",
    "\n",
    "To filter out words from both dictionaries we can go through each word in the gamer dictionary and compare how frequently a word occurrs in both dictionaries. If a word is used too similarly in both language sets then we can remove the word from both. \n",
    "\n",
    "Unfortunately, our dictionary currently stores the number of times a word has been used in a language set and not the percentage of times that a word is used in the entire language set. This is a simple enough thing to code though, and now exists in the form of the `instances_to_decimal` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the is used 6797 times in the gamer dictionary \n",
      "the is used 0.0482714050338049 of the time in the gamer language set\n"
     ]
    }
   ],
   "source": [
    "#create and store the normal dictionary\n",
    "normal_dictionary = csv_to_dict(\"normal.csv\")\n",
    "for word in normal_dictionary:\n",
    "    value = normal_dictionary[word]\n",
    "    normal_dictionary[word] = int(value)\n",
    "\n",
    "#remove infrequent words\n",
    "normal_dictionary_1 = gamer_words.remove_too_uncommon(normal_dictionary,3)\n",
    "\n",
    "gamer_decimal_dictionary = gamer_words.instances_to_decimal(gamer_dictionary_1)\n",
    "normal_decimal_dictionary = gamer_words.instances_to_decimal(normal_dictionary_1)\n",
    "\n",
    "the_usages = gamer_dictionary_1[\"the\"]\n",
    "the_decimal = gamer_decimal_dictionary[\"the\"]\n",
    "print(f\"the is used {the_usages} times in the gamer dictionary \")\n",
    "print(f\"the is used {the_decimal} of the time in the gamer language set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in a usable form, we can parse through our two language sets and remove words that appear a similar percentage of the time in both data sets. While the actual percentage value that is used for this process is arbitrary, we found that removing words with frequency values within +- 15% of each other worked well to find a good set of words.\n",
    "\n",
    "We can use the function `remove_most_common()` to parse our two dictionaries with respect to each other and even output a list of words that were removed from both sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the dictionary is 4334\n"
     ]
    }
   ],
   "source": [
    "normal_decimal_dictionary_1, gamer_decimal_dictionary_1, ignore_list =gamer_words.remove_most_common(normal_decimal_dictionary,gamer_decimal_dictionary)\n",
    "print(f\"the length of the dictionary is {len(gamer_decimal_dictionary_1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we now have two curated language sets, one for the gamer language set and one for the normal language set, we still do not have a method for determining what words are extremely specific to the gamer lexicon. \n",
    "\n",
    "To do this, we can examine all words that appear in both the gamer and the normal dataset, if the word is used 5 times more frequently in the gamer language set than the normal language set, then we can determine it is a gamer word. While this 5x threshold is undoubtedly arbitrary, in testing we found that this value produced a good number of gamer words that were not too over specific, but also not too common as to not be considered gamer specific.\n",
    "\n",
    "Sometimes possible gamer words do not appear at all in the normal language set, so there needs to be a method for these words to become gamer words as well. We foudn that in testing, if a word does not appear in both data sets and its frequency of occurrences values is over .00005 then it can be reasonably considered a gamer word. While this value of .00005 is also arbitrary, we found that using it produces a solid set of gamer words.\n",
    "\n",
    "Using our curated data sets, we can find a number of gamer words using the `determine_gamer_words()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 345 gamer words\n"
     ]
    }
   ],
   "source": [
    "gamer_words_1 = gamer_words.determine_gamer_words(normal_decimal_dictionary_1,gamer_decimal_dictionary_1)\n",
    "\n",
    "print(f\"there are {len(gamer_words_1)} gamer words\")\n",
    "\n",
    "_ = 0\n",
    "#print(gamer_words_1)\n",
    "for word in gamer_words_1:\n",
    "    _ +=1\n",
    "    \n",
    "\n",
    "    #if _ > 25:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_final,gamer_final, gamer_words_final, ignore_final = gamer_words.parse_words(normal_dictionary,gamer_dictionary,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6064562587978671\n",
      "0.014636952445883757\n",
      "0.02413521541503668\n"
     ]
    }
   ],
   "source": [
    "print(gamer_final[\"i\"]/normal_final[\"i\"])\n",
    "print(gamer_final[\"i\"])\n",
    "print(normal_final[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n",
      "['ea', 'battlefront', 'base', 'loot', 'progression', 'battlefield', 'game', 'fifa', 'profile', 'himanshu', 'delete', 'select', 'cards', 'stats', 'franchise', 'releases', 'soul', 'apology', 'gameplay', 'quote', 'differences', 'league', 'legends', 'player', 'tyler1', 'players', 'item', 'clg', 'tsm', 'championship', 'na', 'seed', 'match', 'vs', 'winner', 'bans', 'azir', 'kalista', 'lulu', 'towers', 'yasuo', 'phase', 'champion', 'teammates', 'elo', 'ranked', 'shiny', 'skins', 'champions', 'garen', 'ingame', 'riot', 'casual', 'summoner', 'x', 'lane', 'rank', 'akali', 'challenger', 'jungler', 'u', 'client', 'patch', 'queue', 'solo', 'minions', 'tp', 'gank', 'champ', 'aphelios', 'e', 'ult', 'kills', 'lux', 'g2', 'esports', 'congratulations', 'rng', '1bans', 'xin', 'hmtherald2', 'mmtmountain3', 'bmtbarons5', 'wunder', 'karsa', 'jankos', 'perkz', 'uzi', 'bmtbarons4', 'omtocean3', 'imtinfernal5', 'sincleesin', 'cmtcloud3', 'imtinfernal4', 'omtocean5', 'bmtbarons6', 'postmatch', 'cloud9', 'c9', 'imtinfernal3', 'svenskeren', 'jensen', 'sneaky', 'mmtmountain5', 'matches', 'abilities', 'hp', 'msi', 'sk', 'telecom', 't1', 'tl', 'bmtbarons7', 'bmtbarons9', 'jarvan', 'ivcjarvaniv', 'jackeylove', 'doublelift', 'corejj', 'cmtcloud5', 'skt', 'clid', 'faker', 'caps', 'mikyx', 'bmtbarons8', 'skill', 'option', 'streamers', 'winrate', 'wiki', 'baron', 'buff', 'increases', 'cannon', 'bug', 'freljord', 'minion', 'enemy', 'syndra', 'ryze', 'rift', 'damage', 'remake', 'annie', 'aram', 'afk', 'toxicity', 'armor', 'urgot', 'jungle', 'narrative', 'jax', 'malphite', 'adc', 'rush', 'mid', 'laner', 'bot', 'yuumi', 'reward', 'scout', 'lcs', 'ignar', 'ban', 'yone', 'impressive', 'bronze', 'screenshot', 'sources', 'legendary', 'meta', 'lore', 'fights', 'lp', 'gamer', 'teemo', 'mvp', 'peanut', 'bang', 'wolf', 'spell', 'flash', 'visual', 'passive', 'characters', 'lanes', 'cap', 'resist', 'outdated', 'shadow', 'vgus', 'ezreal', 'ultimate', 'champs', 'excuse', 'riots', 'server', 'runeterra', 'sona', 'cs', 'tft', 'pokemon', 'fatectwistedfate', 'shield', 'lobby', 'mode', 'lec', 'rp', 'eu', 'polish', 'bjergsen', 'biofrost', 'tournament', 'tokens', 'weak', 'void', 'vayne', 'preseason', 'r', 'jhin', 'correct', 'sword', 'galio', 'fnatic', 'fnc', 'twisted', 'bwipo', 'broxah', 'rekkles', 'hylissang', 'powerofevil', 'custom', 'examples', 'blade', 'bugs', 'hmtherald4', 'icon', 'loading', 'darius', 'mechanics', 'zoe', 'seeks', 'vastaya', 'ionia', 'mage', 'magical', 'noxian', 'tribe', 'zaun', 'rune', 'runes', 'noxus', 'yordle', 'demacia', 'naked', 'tree', 'creature', 'souls', 'sun', 'error', 'soraka', 'gambling', 'zed', 'rewards', 'switch', 'auto', 'slot', 'slows', 'cd', 'turret', 'sentinels', 'tag', 'randomly', 'patches', 'shown', 'tab', 'display', 'restart', 'spectate', 'button', 'default', 'versions', 'notification', 'clubs', 'club', 'dot', 'clutch', 'horse', 'solomid', 'stacks', 'formulas', 'dh', 'stack', 'healing', 'percentage', 'ms', 'mechanic', 'formula', '005', 'soft', 'spica', 'microtransactions', 'odyssey', 'animations', 'gen', 'pc', 'ring', 'gamers', 'uswegmen1', 'payment', 'crates', 'hashinshin', 'teemos', 'freak', 'console', 'dlc', 'spanish', 'cosmetic', 'pok√©mon', 'witcher', 'nintendo', 'e3', 'rpg', 'rgames', 'aaa', 'cyberpunk', '2077', 'xbox', 'playstation', 'genre', 'projekt', 'ps4', 'cdpr', 'planets', 'multiplayer', 'critics', 'elden', 'ubisoft', 'blizzard', 'audio', 'imperium', 'nudity', 'chemistry', 'hz']\n"
     ]
    }
   ],
   "source": [
    "print(len(gamer_words_final))\n",
    "print((gamer_words_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suite_life_data/adp1030.csv': [0.11572542788529089, 0.11424546162373007], 'suite_life_data/Bonk.csv': [0.0714009387716252, 0.06638096321951123], 'suite_life_data/cLA.csv': [0.09218463884576775, 0.08745971337158197], 'suite_life_data/crane.csv': [0.10965551354141385, 0.10250149598617035], 'suite_life_data/Firefight451.csv': [0.23558957867261746, 0.22996696261987495], 'suite_life_data/Jiangster.csv': [0.3032867726579211, 0.295173016941167], 'suite_life_data/Kelly Stellmacher.csv': [0.12824787035401852, 0.12132498785079898], 'suite_life_data/Misfortune123.csv': [0.07113193357387446, 0.06599138649080756], 'suite_life_data/notbot.csv': [0.09457795709288658, 0.08741476731800797], 'suite_life_data/pieguy.csv': [0.08083238727727893, 0.07906097176597826], 'suite_life_data/Sier.csv': [0.06969730314834649, 0.06488058468672768]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_list = os.listdir(\"suite_life_data\")\n",
    "\n",
    "file_list = [\"suite_life_data/\" + user for user in file_list]\n",
    "\n",
    "#print(file_list)\n",
    "\n",
    "user_value_dict = {}\n",
    "swap_list = []\n",
    "for user in file_list:\n",
    "\n",
    "    swap_list = []\n",
    "    user_dictionary = csv_to_dict(user)\n",
    "    #print(user_dictionary)\n",
    "    for word in user_dictionary:\n",
    "        value = user_dictionary[word]\n",
    "        user_dictionary[word] = int(value)\n",
    "    \n",
    "    user_dictionary = gamer_words.remove_too_uncommon(user_dictionary.copy(),3)\n",
    "    user_dictionary = {word:value for (word,value) in user_dictionary.items() if word not in ignore_final}\n",
    "    #print(type(user_dictionary))\n",
    "    user_dictionary = gamer_words.instances_to_decimal(user_dictionary.copy())\n",
    "\n",
    "    #print(user_dictionary)\n",
    "    #print(type(user_dictionary))\n",
    "    swap_list.append(gamer_words.determine_language_similarity(gamer_final.copy(),user_dictionary.copy()))\n",
    "    swap_list.append(gamer_words.determine_language_similarity(normal_final.copy(),user_dictionary.copy()))\n",
    "    \n",
    "    user_value_dict[user] = swap_list\n",
    "\n",
    "print(user_value_dict)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8b9e368c7c6bad9dfe3af1d0bc5bd8bf44c53ff0319eea12fd05f99021ec489"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
